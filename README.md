# SEM Kurumsal Bilgi Chatbot'u

Bu proje, SEM ÅŸirketinin kurumsal dokÃ¼manlarÄ± Ã¼zerinde Sorgu-Cevaplama (Q&A) yapabilen, **Retrieval-Augmented Generation (RAG)** mimarisine dayalÄ± bir chatbot uygulamasÄ±dÄ±r. Chatbot, Flask tabanlÄ± bir web arayÃ¼zÃ¼ Ã¼zerinden kullanÄ±cÄ±larla etkileÅŸime geÃ§er ve Google'Ä±n Gemini Pro modelini kullanarak doÄŸal dilde cevaplar Ã¼retir.

## ğŸš€ Projenin AmacÄ±

Projenin temel amacÄ±, ÅŸirket iÃ§i veya dÄ±ÅŸÄ± kullanÄ±cÄ±larÄ±n, SEM'in hizmetleri, teknolojileri, baÅŸarÄ± hikayeleri ve operasyonel yapÄ±sÄ± hakkÄ±ndaki sorularÄ±na, saÄŸlanan PDF dokÃ¼manlarÄ±na dayanarak anÄ±nda, doÄŸru ve kapsamlÄ± cevaplar vermektir.

## ğŸ› ï¸ Teknoloji ve Mimarisi

Proje, modern bir RAG (Retrieval-Augmented Generation) mimarisine dayanmaktadÄ±r. Her bir bileÅŸenin belirli bir gÃ¶revi vardÄ±r:

-   **Web ArayÃ¼zÃ¼:** `Flask`
-   **LLM (BÃ¼yÃ¼k Dil Modeli):** `Google Gemini Pro`
-   **Embedding Modeli:** `all-MiniLM-L6-v2` (Sentence-Transformers)
-   **VektÃ¶r VeritabanÄ±:** `FAISS` (Facebook AI Similarity Search)
-   **DokÃ¼man Ä°ÅŸleme:** `PyMuPDF`, `LangChain`
-   **Dil:** `Python`

### Proje Dosya YapÄ±sÄ±
<pre> chatbot_env/
company_docs/
rag_chatbot/
    __pycache__/
    __init__.py
    chatbot.py
    document_loader.py
    embedding.py
    llm.py
    vector_store.py
static/
templates/
    index.html
.env
.gitignore
app.py
deneme.md
faiss_index.bin
faiss_metadata.pkl
README.md
requirements.txt
</pre>


---

## â­ En Kritik Konsept: DokÃ¼man ParÃ§alama (Chunking)

Bu projenin baÅŸarÄ±sÄ±, bÃ¼yÃ¼k Ã¶lÃ§Ã¼de dokÃ¼manlarÄ±n nasÄ±l parÃ§alandÄ±ÄŸÄ±na (**chunking**) baÄŸlÄ±dÄ±r. LLM'ler, onlara doÄŸrudan verilmeyen bilgiyi bilemezler. **DoÄŸru bilgiyi bulup LLM'e sunmak, RAG sisteminin en Ã¶nemli ve en zorlu gÃ¶revidir.**

### KarÅŸÄ±laÅŸÄ±lan Zorluk ve Ã‡Ã¶zÃ¼m

BaÅŸlangÄ±Ã§ta, dokÃ¼manlar sadece sabit bir karakter sayÄ±sÄ±na gÃ¶re bÃ¶lÃ¼ndÃ¼. Bu yÃ¶ntem iki temel soruna yol aÃ§tÄ±:
1.  **BaÄŸlam KaybÄ±:** Bir baÅŸlÄ±k altÄ±ndaki Ã¶nemli bilgiler, farklÄ± chunk'lara daÄŸÄ±larak anlamsal bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ yitirdi.
2.  **Devasa Chunk'lar:** `MarkdownHeaderTextSplitter` tek baÅŸÄ±na kullanÄ±ldÄ±ÄŸÄ±nda, bir baÅŸlÄ±k altÄ±ndaki tÃ¼m metni tek bir devasa chunk olarak aldÄ±. Bu da "sem ne iÅŸ yapar" gibi genel sorularda on binlerce token'lÄ±k girdi maliyetine ve dÃ¼ÅŸÃ¼k alaka puanlarÄ±na neden oldu.

**Uygulanan Ã‡Ã¶zÃ¼m: Hibrit ParÃ§alama Stratejisi**

Bu sorunu Ã§Ã¶zmek iÃ§in `document_loader.py` dosyasÄ±nda iki aÅŸamalÄ±, hibrit bir parÃ§alama stratejisi geliÅŸtirildi:

1.  **Ã–nce BaÄŸlama GÃ¶re BÃ¶l:** PDF dokÃ¼manÄ±, iÃ§indeki baÅŸlÄ±k yapÄ±larÄ± (`1.`, `1.1.`, `SECTION 1` vb.) Regex ile tanÄ±nÄ±p standart Markdown baÅŸlÄ±klarÄ±na (`#`, `##`) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. ArdÄ±ndan `MarkdownHeaderTextSplitter` ile metin, baÅŸlÄ±klarÄ±na gÃ¶re bÃ¼yÃ¼k, baÄŸlamÄ± korunmuÅŸ parÃ§alara ayrÄ±lÄ±r.
2.  **Sonra Boyuta GÃ¶re BÃ¶l:** Bu bÃ¼yÃ¼k parÃ§alarÄ±n her biri, `RecursiveCharacterTextSplitter` kullanÄ±larak **512 karakterlik** daha kÃ¼Ã§Ã¼k ve yÃ¶netilebilir chunk'lara bÃ¶lÃ¼nÃ¼r. Bu iÅŸlem sÄ±rasÄ±nda, her kÃ¼Ã§Ã¼k chunk'a ait olduÄŸu ana baÅŸlÄ±ÄŸÄ±n metadata'sÄ± miras bÄ±rakÄ±lÄ±r.

Bu hibrit yaklaÅŸÄ±m sayesinde, her bir chunk hem yÃ¶netilebilir boyuttadÄ±r (maliyet ve verimlilik iÃ§in) hem de hangi baÅŸlÄ±ÄŸa ait olduÄŸunu "bilir" (baÄŸlam ve doÄŸruluk iÃ§in).

### Alaka PuanÄ± ve EÅŸik DeÄŸeri

Arama doÄŸruluÄŸunu artÄ±rmak ve gereksiz LLM Ã§aÄŸrÄ±larÄ±nÄ± Ã¶nlemek iÃ§in **KosinÃ¼s BenzerliÄŸi** (`IndexFlatIP`) tabanlÄ± bir arama endeksi kullanÄ±lmÄ±ÅŸtÄ±r. Bu, 0 ile 1 arasÄ±nda anlamlÄ± bir "alaka puanÄ±" Ã¼retir.
-   KullanÄ±cÄ± sorgusuna verilen cevaplarÄ±n alaka puanÄ±, belirlenen bir eÅŸik deÄŸerinin (`score_threshold`) altÄ±nda kalÄ±rsa, LLM'e boÅŸ `context` gÃ¶nderilir. Bu, sistemin ilgisiz konularda "bilmiyorum" demesini saÄŸlar ve maliyeti ciddi oranda dÃ¼ÅŸÃ¼rÃ¼r.

---

## ğŸš€ Projeyi Ã‡alÄ±ÅŸtÄ±rma

1.  **Depoyu KlonlayÄ±n:**
    ```bash
    git clone [repo-url]
    cd [repo-adÄ±]
    ```

2.  **Sanal Ortam OluÅŸturun ve Aktive Edin:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # macOS/Linux iÃ§in
    # venv\Scripts\activate    # Windows iÃ§in
    ```

3.  **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ortam DeÄŸiÅŸkenlerini AyarlayÄ±n:**
    -   Proje ana dizininde `.env` adÄ±nda bir dosya oluÅŸturun.
    -   `.env` dosyasÄ±nÄ±n iÃ§ine Google Gemini API anahtarÄ±nÄ±zÄ± ve aÅŸaÄŸÄ±daki konfigÃ¼rasyonu girin:
        ```env
        GEMINI_API_KEY="AIzaSy..."
        TOKENIZERS_PARALLELISM=false
        ```

5.  **DokÃ¼manlarÄ±nÄ±zÄ± Ekleyin:**
    -   Bilgi kaynaÄŸÄ± olarak kullanÄ±lacak tÃ¼m PDF dosyalarÄ±nÄ±zÄ± `company_docs` klasÃ¶rÃ¼nÃ¼n iÃ§ine koyun.

6.  **UygulamayÄ± BaÅŸlatÄ±n:**
    ```bash
    flask run
    ```
    Uygulama baÅŸladÄ±ÄŸÄ±nda, `company_docs` klasÃ¶rÃ¼ndeki dokÃ¼manlarÄ± iÅŸleyerek `faiss_index.bin` ve `faiss_metadata.pkl` dosyalarÄ±nÄ± otomatik olarak oluÅŸturacaktÄ±r. Bu iÅŸlem, dokÃ¼man sayÄ±sÄ±na baÄŸlÄ± olarak birkaÃ§ dakika sÃ¼rebilir. *Not: Mevcut bir veritabanÄ±nÄ± yeniden oluÅŸturmak iÃ§in bu iki dosyayÄ± manuel olarak silmeniz gerekir.*

7.  **ArayÃ¼ze EriÅŸin:**
    -   TarayÄ±cÄ±nÄ±zÄ± aÃ§Ä±n ve `http://127.0.0.1:5000` adresine gidin.

## ğŸ”® Gelecek Ä°yileÅŸtirmeler

-   **Ä°ndeksleme Script'i:** VektÃ¶r veritabanÄ± oluÅŸturma sÃ¼recini, web uygulamasÄ±nÄ±n baÅŸlangÄ±cÄ±ndan ayÄ±rÄ±p ayrÄ± bir `build_index.py` script'ine taÅŸÄ±mak, uygulamanÄ±n daha hÄ±zlÄ± baÅŸlamasÄ±nÄ± saÄŸlar.
-   **Sohbet GeÃ§miÅŸi:** KonuÅŸmanÄ±n baÄŸlamÄ±nÄ± hatÄ±rlayabilmesi iÃ§in sohbet geÃ§miÅŸi (chat history) Ã¶zelliÄŸi eklenebilir.
-   **GeliÅŸmiÅŸ Retriever'lar:** Daha karmaÅŸÄ±k sorgular iÃ§in `ParentDocumentRetriever` veya `Self-Querying Retriever` gibi LangChain'in geliÅŸmiÅŸ arama mekanizmalarÄ± entegre edilebilir.
-   **KullanÄ±cÄ± ArayÃ¼zÃ¼:** CevaplarÄ±n daha iyi formatlanmasÄ± (Markdown render) ve "streaming" (cevaplarÄ±n kelime kelime gelmesi) gibi Ã¶zelliklerle arayÃ¼z zenginleÅŸtirilebilir.