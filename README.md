# SEM Kurumsal Bilgi Chatbot'u

Bu proje, SEM ÅŸirketinin kurumsal dokÃ¼manlarÄ± Ã¼zerinde Sorgu-Cevaplama (Q&A) yapabilen, **Retrieval-Augmented Generation (RAG)** mimarisine dayalÄ± bir chatbot uygulamasÄ±dÄ±r. Chatbot, Flask tabanlÄ± bir web arayÃ¼zÃ¼ Ã¼zerinden kullanÄ±cÄ±larla etkileÅŸime geÃ§er ve Google'Ä±n Gemini Pro modelini kullanarak doÄŸal dilde cevaplar Ã¼retir.

## ğŸš€ Projenin AmacÄ±

Projenin temel amacÄ±, ÅŸirket iÃ§i veya dÄ±ÅŸÄ± kullanÄ±cÄ±larÄ±n, SEM'in hizmetleri, teknolojileri, baÅŸarÄ± hikayeleri ve operasyonel yapÄ±sÄ± hakkÄ±ndaki sorularÄ±na, saÄŸlanan PDF dokÃ¼manlarÄ±na dayanarak anÄ±nda, doÄŸru ve kapsamlÄ± cevaplar vermektir.

## ğŸ› ï¸ Teknoloji ve Mimarisi

Proje, modern bir RAG (Retrieval-Augmented Generation) mimarisine dayanmaktadÄ±r. Her bir bileÅŸenin belirli bir gÃ¶revi vardÄ±r:

-   **Web ArayÃ¼zÃ¼:** `Flask`
-   **LLM (BÃ¼yÃ¼k Dil Modeli):** `Google Gemini Pro`
-   **Embedding Modeli:** `all-MiniLM-L6-v2` (Sentence-Transformers)
-   **VektÃ¶r VeritabanÄ±:** `FAISS` (Facebook AI Similarity Search)
-   **DokÃ¼man Ä°ÅŸleme:** `PyMuPDF`, `LangChain`
-   **Dil:** `Python`

### Proje Dosya YapÄ±sÄ±
<pre> chatbot_env/
company_docs/
rag_chatbot/
    __pycache__/
    __init__.py
    chatbot.py
    document_loader.py
    embedding.py
    llm.py
    vector_store.py
static/
templates/
    index.html
.env
.gitignore
app.py
deneme.md
faiss_index.bin
faiss_metadata.pkl
README.md
requirements.txt
</pre>


---

## â­ En Kritik Konsept: DokÃ¼man ParÃ§alama (Chunking)

Bu projenin baÅŸarÄ±sÄ±, bÃ¼yÃ¼k Ã¶lÃ§Ã¼de dokÃ¼manlarÄ±n nasÄ±l parÃ§alandÄ±ÄŸÄ±na (**chunking**) baÄŸlÄ±dÄ±r. LLM'ler, onlara doÄŸrudan verilmeyen bilgiyi bilemezler. **DoÄŸru bilgiyi bulup LLM'e sunmak, RAG sisteminin en Ã¶nemli ve en zorlu gÃ¶revidir.**

### KarÅŸÄ±laÅŸÄ±lan Zorluk ve Ã‡Ã¶zÃ¼m

BaÅŸlangÄ±Ã§ta, dokÃ¼manlar sadece sabit bir karakter sayÄ±sÄ±na gÃ¶re bÃ¶lÃ¼ndÃ¼. Bu yÃ¶ntem iki temel soruna yol aÃ§tÄ±:
1.  **BaÄŸlam KaybÄ±:** Bir baÅŸlÄ±k altÄ±ndaki Ã¶nemli bilgiler, farklÄ± chunk'lara daÄŸÄ±larak anlamsal bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ yitirdi.
2.  **Devasa Chunk'lar:** `MarkdownHeaderTextSplitter` tek baÅŸÄ±na kullanÄ±ldÄ±ÄŸÄ±nda, bir baÅŸlÄ±k altÄ±ndaki tÃ¼m metni tek bir devasa chunk olarak aldÄ±. Bu da "sem ne iÅŸ yapar" gibi genel sorularda on binlerce token'lÄ±k girdi maliyetine ve dÃ¼ÅŸÃ¼k alaka puanlarÄ±na neden oldu.

**Uygulanan Ã‡Ã¶zÃ¼m: Hibrit ParÃ§alama Stratejisi**

Bu sorunu Ã§Ã¶zmek iÃ§in `document_loader.py` dosyasÄ±nda iki aÅŸamalÄ±, hibrit bir parÃ§alama stratejisi geliÅŸtirildi:

1.  **Ã–nce BaÄŸlama GÃ¶re BÃ¶l:** PDF dokÃ¼manÄ±, iÃ§indeki baÅŸlÄ±k yapÄ±larÄ± (`1.`, `1.1.`, `SECTION 1` vb.) Regex ile tanÄ±nÄ±p standart Markdown baÅŸlÄ±klarÄ±na (`#`, `##`) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. ArdÄ±ndan `MarkdownHeaderTextSplitter` ile metin, baÅŸlÄ±klarÄ±na gÃ¶re bÃ¼yÃ¼k, baÄŸlamÄ± korunmuÅŸ parÃ§alara ayrÄ±lÄ±r.
2.  **Sonra Boyuta GÃ¶re BÃ¶l:** Bu bÃ¼yÃ¼k parÃ§alarÄ±n her biri, `RecursiveCharacterTextSplitter` kullanÄ±larak **512 karakterlik** daha kÃ¼Ã§Ã¼k ve yÃ¶netilebilir chunk'lara bÃ¶lÃ¼nÃ¼r. Bu iÅŸlem sÄ±rasÄ±nda, her kÃ¼Ã§Ã¼k chunk'a ait olduÄŸu ana baÅŸlÄ±ÄŸÄ±n metadata'sÄ± miras bÄ±rakÄ±lÄ±r.

Bu hibrit yaklaÅŸÄ±m sayesinde, her bir chunk hem yÃ¶netilebilir boyuttadÄ±r (maliyet ve verimlilik iÃ§in) hem de hangi baÅŸlÄ±ÄŸa ait olduÄŸunu "bilir" (baÄŸlam ve doÄŸruluk iÃ§in).

### Alaka PuanÄ± ve EÅŸik DeÄŸeri

Arama doÄŸruluÄŸunu artÄ±rmak ve gereksiz LLM Ã§aÄŸrÄ±larÄ±nÄ± Ã¶nlemek iÃ§in **KosinÃ¼s BenzerliÄŸi** (`IndexFlatIP`) tabanlÄ± bir arama endeksi kullanÄ±lmÄ±ÅŸtÄ±r. Bu, 0 ile 1 arasÄ±nda anlamlÄ± bir "alaka puanÄ±" Ã¼retir.
-   KullanÄ±cÄ± sorgusuna verilen cevaplarÄ±n alaka puanÄ±, belirlenen bir eÅŸik deÄŸerinin (`score_threshold`) altÄ±nda kalÄ±rsa, LLM'e boÅŸ `context` gÃ¶nderilir. Bu, sistemin ilgisiz konularda "bilmiyorum" demesini saÄŸlar ve maliyeti ciddi oranda dÃ¼ÅŸÃ¼rÃ¼r.

---

## ğŸ“Š Token Analizi ve Maliyet Raporu

### **Mevcut Durum:**
- **Toplam DokÃ¼man:** 113,749 karakter
- **Toplam Token (Gemini API):** 25,215 token
- **Sorgu baÅŸÄ±na maliyet:** $0.002041
- **AylÄ±k maliyet tahminleri:**
  - 10 sorgu/gÃ¼n: $0.61/ay
  - 100 sorgu/gÃ¼n: $6.12/ay
  - 1000 sorgu/gÃ¼n: $61.23/ay

### **Tek Sorgu Analizi:**
- **Sistem prompt:** 37 token
- **Context (2000 karakter):** 399 token
- **KullanÄ±cÄ± sorgusu:** 5 token
- **Toplam:** 441 token

**Token Analizi Scripti:** `test_token.py` dosyasÄ± ile detaylÄ± analiz yapÄ±labilir.

## ğŸš€ Optimizasyon Ã–nerileri

### **1. Token Optimizasyonu (Ã–ncelik 1):**
- **Chunk boyutu kÃ¼Ã§Ã¼ltme:** 400 â†’ 300 karakter
- **Daha yÃ¼ksek similarity threshold:** 0.25 â†’ 0.35
- **Context window sÄ±nÄ±rÄ±:** Maksimum 3 chunk kullan
- **Query classification:** Basit sorular iÃ§in daha az context

### **2. Retrieval Ä°yileÅŸtirmeleri:**
- **Hybrid search:** Semantic + keyword search
- **Query expansion:** EÅŸ anlamlÄ± kelimeler ekle
- **Document ranking:** Relevance score'a gÃ¶re sÄ±ralama
- **Negative sampling:** Ä°lgisiz dokÃ¼manlarÄ± filtrele

### **3. Caching Stratejileri:**
- **Response caching:** SÄ±k sorulan sorular iÃ§in
- **Embedding caching:** AynÄ± query'ler iÃ§in
- **Context caching:** Benzer dokÃ¼manlar iÃ§in
- **Session-based caching:** KullanÄ±cÄ± baÅŸÄ±na

### **4. Advanced RAG Teknikleri:**
- **Self-querying:** Query'yi kategorize et
- **Multi-hop reasoning:** Birden fazla dokÃ¼man kullan
- **Query rewriting:** Sorguyu optimize et
- **Contextual compression:** Gereksiz bilgileri Ã§Ä±kar

## ğŸ’» Kod GeliÅŸtirmeleri

### **1. Performans Optimizasyonu:**
```python
# Async processing
async def process_multiple_queries()
# Connection pooling
# Background indexing
# Lazy loading
```

### **2. Hata YÃ¶netimi:**
```python
# Retry mechanism
# Graceful degradation
# Fallback responses
# Health checks
```

### **3. Monitoring & Analytics:**
```python
# Query analytics
# Token usage tracking
# Performance metrics
# User behavior analysis
```

### **4. GÃ¼venlik Ä°yileÅŸtirmeleri:**
```python
# Rate limiting
# Input validation
# SQL injection protection
# XSS prevention
```

## ğŸ”§ Debug ve Test AraÃ§larÄ±

### **Chunk Analizi:**
- **chunks.txt dosyasÄ±:** TÃ¼m chunk'larÄ± test amaÃ§lÄ± dÄ±ÅŸa aktarma
- **âš ï¸ Dikkat:** chunks.txt dosyasÄ± test sonrasÄ± silinmelidir (hassas bilgi iÃ§erebilir)
- **KullanÄ±m:** Debug ve chunk kalitesi analizi iÃ§in

---

## ğŸš€ Projeyi Ã‡alÄ±ÅŸtÄ±rma

1.  **Depoyu KlonlayÄ±n:**
    ```bash
    git clone [repo-url]
    cd [repo-adÄ±]
    ```

2.  **Sanal Ortam OluÅŸturun ve Aktive Edin:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # macOS/Linux iÃ§in
    # venv\Scripts\activate    # Windows iÃ§in
    ```

3.  **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ortam DeÄŸiÅŸkenlerini AyarlayÄ±n:**
    -   Proje ana dizininde `.env` adÄ±nda bir dosya oluÅŸturun.
    -   `.env` dosyasÄ±nÄ±n iÃ§ine Google Gemini API anahtarÄ±nÄ±zÄ± ve aÅŸaÄŸÄ±daki konfigÃ¼rasyonu girin:
        ```env
        GEMINI_API_KEY="AIzaSy..."
        TOKENIZERS_PARALLELISM=false
        ```

5.  **DokÃ¼manlarÄ±nÄ±zÄ± Ekleyin:**
    -   Bilgi kaynaÄŸÄ± olarak kullanÄ±lacak tÃ¼m PDF dosyalarÄ±nÄ±zÄ± `company_docs` klasÃ¶rÃ¼nÃ¼n iÃ§ine koyun.

6.  **UygulamayÄ± BaÅŸlatÄ±n:**
    ```bash
    flask run
    ```
    Uygulama baÅŸladÄ±ÄŸÄ±nda, `company_docs` klasÃ¶rÃ¼ndeki dokÃ¼manlarÄ± iÅŸleyerek `faiss_index.bin` ve `faiss_metadata.pkl` dosyalarÄ±nÄ± otomatik olarak oluÅŸturacaktÄ±r. Bu iÅŸlem, dokÃ¼man sayÄ±sÄ±na baÄŸlÄ± olarak birkaÃ§ dakika sÃ¼rebilir. *Not: Mevcut bir veritabanÄ±nÄ± yeniden oluÅŸturmak iÃ§in bu iki dosyayÄ± manuel olarak silmeniz gerekir.*

7.  **ArayÃ¼ze EriÅŸin:**
    -   TarayÄ±cÄ±nÄ±zÄ± aÃ§Ä±n ve `http://127.0.0.1:5000` adresine gidin.

## ğŸ”® Gelecek Ä°yileÅŸtirmeler

-   **Ä°ndeksleme Script'i:** VektÃ¶r veritabanÄ± oluÅŸturma sÃ¼recini, web uygulamasÄ±nÄ±n baÅŸlangÄ±cÄ±ndan ayÄ±rÄ±p ayrÄ± bir `build_index.py` script'ine taÅŸÄ±mak, uygulamanÄ±n daha hÄ±zlÄ± baÅŸlamasÄ±nÄ± saÄŸlar.
-   **Sohbet GeÃ§miÅŸi:** KonuÅŸmanÄ±n baÄŸlamÄ±nÄ± hatÄ±rlayabilmesi iÃ§in sohbet geÃ§miÅŸi (chat history) Ã¶zelliÄŸi eklenebilir.
-   **GeliÅŸmiÅŸ Retriever'lar:** Daha karmaÅŸÄ±k sorgular iÃ§in `ParentDocumentRetriever` veya `Self-Querying Retriever` gibi LangChain'in geliÅŸmiÅŸ arama mekanizmalarÄ± entegre edilebilir.
-   **KullanÄ±cÄ± ArayÃ¼zÃ¼:** CevaplarÄ±n daha iyi formatlanmasÄ± (Markdown render) ve "streaming" (cevaplarÄ±n kelime kelime gelmesi) gibi Ã¶zelliklerle arayÃ¼z zenginleÅŸtirilebilir.